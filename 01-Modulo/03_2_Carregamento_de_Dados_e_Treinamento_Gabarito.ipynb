{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03.2 - Carregamento de Dados e Treinamento - Gabarito.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOa2UImxPAxz",
        "colab_type": "text"
      },
      "source": [
        "# Passo à Passo das Redes Neurais\n",
        "\n",
        "A criação e treinamento de uma rede neural tem alguns passos que foram um *pipeline* completo.\n",
        "Nesta aula, vamos ver cada passo para criar e treinar uma rede neural do zero usando PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gocdcIdRhXm",
        "colab_type": "text"
      },
      "source": [
        "## Imports e configurações iniciais\n",
        "\n",
        "Agora que a brincadeira está ficando séria, que tal uma sugestão de como organizar o seu código? Para facilitar o entendimento e manutenção do código, mantenha sempre no início os seguintes elementos:\n",
        "* imports de pacotes\n",
        "* configuração de **hiperparâmetros**\n",
        "* definição do hardware padrão utilizado\n",
        "\n",
        "Nessa aula vamos trabalhar com dados reais, então **vamos precisar de GPU!** Então não se esqueça de mudar as configurações desse ambiente do colab. <br>\n",
        "Sugiro rodar esse mesmo código sem GPU em outro momento, só pra sentir o gostinho de como a GPU facilitou o uso de redes neurais.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DB-I9n6O-a8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Basic imports.\n",
        "import os, sys, time\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.backends import cudnn\n",
        "cudnn.benchmark = True\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils import data\n",
        "\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "from skimage import io\n",
        "\n",
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VfLxDw2PtQJ",
        "colab_type": "text"
      },
      "source": [
        "Nesta célula, além da definição do hardware padrão, estão também definidos os hiperparâmetros do nosso modelo. Mais à frente conversaremos um pouco melhor sobre eles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B90MLWU3Pdih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setting predefined arguments.\n",
        "args = {\n",
        "    'num_epochs': 20,      # Number of epochs.\n",
        "    'num_classes': 10,     # Number of classes.\n",
        "    'lr': 1e-3,            # Learning rate.\n",
        "    'weight_decay': 5e-4,  # L2 penalty.\n",
        "    'num_workers': 3,      # Number of workers on data loader.\n",
        "    'batch_size': 50,      # Mini-batch size.\n",
        "}\n",
        "\n",
        "# Setting device (CPU | CUDA)\n",
        "if torch.cuda.is_available():\n",
        "    args['device'] = torch.device('cuda')\n",
        "else:\n",
        "    args['device'] = torch.device('cpu')\n",
        "\n",
        "print(args['device'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOOUl5wxWyk0",
        "colab_type": "text"
      },
      "source": [
        "## Carregamento de Dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCk5Deo8XFH9",
        "colab_type": "text"
      },
      "source": [
        "#### **Datasets**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4u-kbpgRT76",
        "colab_type": "text"
      },
      "source": [
        "O PyTorch possui dois pacotes que trazem datasets prontos para uso.\n",
        "\n",
        "* Torchtext: https://torchtext.readthedocs.io/en/latest/datasets.html\n",
        "* Torchvision: https://pytorch.org/docs/stable/torchvision/datasets.html\n",
        "\n",
        "Como os nomes indicam, são datasets de textos (text) e imagens (vision), duas aplicações onde redes neurais são muito bem sucedidas.\n",
        "\n",
        "Para aplicações com textos e outros tipos de séries temporais, o carregamento de dados possui nuances que dificultam o entendimento, portanto vamos concentrar no carregamento de imagens.\n",
        "\n",
        "Para trabalhar com datasets do pacote torchvision, basta\n",
        "* Importar o pacote\n",
        "``` python \n",
        "from torchvision import datasets \n",
        "```\n",
        "* Carregar o dataset do seu interesse (ex: MNIST)\n",
        "``` python \n",
        "data = datasets.MNIST(root, train=True, transform=None, target_transform=None, download=False)\n",
        "```\n",
        "\n",
        "> Note que o torch faz o carregamento das imagens no formato [Pillow](https://pillow.readthedocs.io/en/stable/). Portanto é necessário convertê-las para um tensor usando um [**Transformer**](https://pytorch.org/docs/stable/torchvision/transforms.html).\n",
        "\n",
        "* Importar o pacote transforms\n",
        "``` python \n",
        "from torchvision import transforms \n",
        "```\n",
        "* preencher o parâmetro ```transform``` do dataset com a função que converte para tensor.\n",
        "``` python \n",
        "transforms.ToTensor() \n",
        "```\n",
        "\n",
        "Pronto! Quando seu dado for carregado, ele passará pela transformação indicada no parâmetro ```transform```, que nesse caso converte o dado para um tensor.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_AvEAUfR0r9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_set = datasets.MNIST('./', \n",
        "                           train=True, \n",
        "                           transform=transforms.ToTensor(),\n",
        "                           download=True)\n",
        "\n",
        "test_set = datasets.MNIST('./', \n",
        "                           train=False, \n",
        "                           transform=transforms.ToTensor(),\n",
        "                           download=False)\n",
        "\n",
        "print('Amostras de treino: ' + str(len(train_set)) + '\\nAmostras de Teste:' + str(len(test_set)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hISPaTXvTYso",
        "colab_type": "text"
      },
      "source": [
        "Cada dataset possui uma implementação específica internamente no pytorch. Verifique o ```type``` da variável que recebeu os dados e veja que se refere a uma classe específica do dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qbp9GP1YU1Ru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(type(train_set))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlSbrnrYU1rv",
        "colab_type": "text"
      },
      "source": [
        "Por se tratar de um conjunto de dados **supervisionado**, cada elemento do dataset é definido por uma tupla `(dado, rótulo)`. Para dados não supervisionados, cada elemento do dataset comporta apenas o dado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grBOLD1yU68x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(type(train_set[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHU7iIkTVYhS",
        "colab_type": "text"
      },
      "source": [
        "Podemos então iterar no dataset para observar algumas amostras e seus rótulos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VegU7Q0SVYBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(3):\n",
        "  dado, rotulo = train_set[i]\n",
        "  \n",
        "  plt.figure()\n",
        "  plt.imshow(dado[0])\n",
        "  plt.title('Rotulo: '+ str(rotulo))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrfiXMDdViAs",
        "colab_type": "text"
      },
      "source": [
        "Temos um total de 70 mil amostras, mas elas **ainda não estão carregadas na memória** (isso seria bastante custoso). A vantagem da classe ```Dataset``` do Pytorch é que as amostras só são carregadas quando necessário.\n",
        "\n",
        "Para entender melhor, vamos experimentar a transformação a seguir\n",
        "```python\n",
        "transforms.RandomCrop(12)\n",
        "```\n",
        "Essa função realiza um recorte aleatório de ```12 x 12``` (pixels) na imagem. Ao carregar a mesma amostra múltiplas vezes, um novo recorte será feito. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oXnlMnqVsKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "crop_set = datasets.MNIST('./', \n",
        "                           train=False, \n",
        "                           transform=transforms.RandomCrop(12),\n",
        "                           download=False)\n",
        "\n",
        "# Tuple (dado, rótulo)\n",
        "for i in range(3):\n",
        "  dado, rotulo = crop_set[0]\n",
        "  \n",
        "  plt.figure()\n",
        "  plt.imshow(dado)\n",
        "  plt.title('Rótulo: '+ str(rotulo))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSbsVf36Vs9E",
        "colab_type": "text"
      },
      "source": [
        "Em resumo, cada vez que indexamos um item do dataset, as seguintes operações são realizadas:\n",
        "* Amostra lida do arquivo e carregada como uma tupla ```(dado, rótulo)```\n",
        "* As transformações são aplicadas \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hL3Kokw3XCqq",
        "colab_type": "text"
      },
      "source": [
        "#### **Dataloader**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOtixwnbWcKP",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "O [Dataloader](https://pytorch.org/docs/stable/data.html?highlight=dataloader#torch.utils.data.DataLoader) gerencia muito bem o carregamento de dados para o treinamento de redes neurais, trazendo as funções: \n",
        "\n",
        "* Separação dos dados em batches\n",
        "* Embaralhando os dados\n",
        "* Carregando batches em paralelo utilizando threads\n",
        "\n",
        "O uso de threads no carregamento minimiza períodos ociosos de processamento, visto que a leitura de dados em arquivo é um grande gargalo de tempo.\n",
        "\n",
        "As três funcionalidades que acabamos de conhecer são controladas pelos parâmetros da chamada do DataLoader.\n",
        "```python\n",
        "loader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=4)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIeFM-UTWMLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(train_set, \n",
        "                          batch_size=args['batch_size'], \n",
        "                          shuffle=True, \n",
        "                          num_workers=args['num_workers'])\n",
        "\n",
        "test_loader = DataLoader(test_set, \n",
        "                          batch_size=args['batch_size'], \n",
        "                          shuffle=True, \n",
        "                          num_workers=args['num_workers'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlVojbufWkzp",
        "colab_type": "text"
      },
      "source": [
        "O objeto retornado é um **iterador**, podendo ser utilizado para iterar em loops mas não suportando indexação."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZR7Y4BnWokd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for batch in train_loader:\n",
        "  \n",
        "  dado, rotulo = batch\n",
        "  print(dado.size(), rotulo.size())\n",
        "\n",
        "  plt.imshow(dado[0][0])\n",
        "  plt.title('Rotulo: '+ str(rotulo[0]) )\n",
        "  break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdavQcjZ5l5-",
        "colab_type": "text"
      },
      "source": [
        "Vale a pena visitar o [tutorial de carregamento de dados do PyTorch](https://pytorch.org/tutorials/beginner/data_loading_tutorial.html) que introduz o uso das classes Dataset e Dataloader."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZdIbgSnXgXj",
        "colab_type": "text"
      },
      "source": [
        "## Definindo a Arquitetura"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdvZzxR8Xjsp",
        "colab_type": "text"
      },
      "source": [
        "#### **Classe nn.Module**\n",
        "\n",
        "O [nn.Module](https://pytorch.org/docs/stable/nn.html#torch.nn.Module) é a classe base para todos os módulos de redes neurais. \n",
        "\n",
        "A forma mais organizada de definir modelos em PyTorch é implementando uma classe. Para redes pequenas, como as que estamos aprendendo até o momento, sua importância pode não se destacar, mas modelos maiores e com funcionalidades mais complexas, são mais fáceis de implementar e realizar manutenções dessa forma.\n",
        "\n",
        "Para implementar uma subclasse da ```nn.Module``` basta definir a subclasse da seguinte forma:\n",
        "```python\n",
        "class MinhaRede(nn.Module):\n",
        "  # resto do código\n",
        "```\n",
        "\n",
        "Funções obrigatórias de subclasses da ```nn.Module```.\n",
        "* ```__init()__```: definição da arquitetura da rede no estado interno da classe.\n",
        "* ```forward()```: Fluxo da entrada ao longo da rede e retorno da saída."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwUcDlWwDIFF",
        "colab_type": "text"
      },
      "source": [
        "**Implemente a seguir** um Multi-Layer Perceptron (MLP) intercalando camadas do tipo [`Linear`](https://pytorch.org/docs/stable/nn.html#torch.nn.Linear) com funções de ativação `ReLU`. \n",
        "\n",
        "\n",
        "Ainda falaremos mais sobre funções de ativação, mas para entender a importância das funções de ativação não-lineares após cada camada, visite a [demo de Stanford](https://cs.stanford.edu/people/karpathy/convnetjs/demo/classify2d.html). Ao remover as ativações não-lineares a rede se torna incapaz de aprender soluções não-lineares.<br>\n",
        "A ativação pode ser definida de duas formas:\n",
        "* Definida no `__init__()` [como uma camada](https://pytorch.org/docs/stable/nn.html?highlight=relu#torch.nn.ReLU) e aplicada no `forward()`\n",
        "```python\n",
        "# No __init__()\n",
        "self.relu = nn.ReLU()\n",
        "# No forward()\n",
        "saida = self.relu(entrada)\n",
        "```\n",
        "\n",
        "* Apenas aplicada no `forward()` [como uma function](https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.relu):\n",
        "```python\n",
        "saida = F.relu(entrada)\n",
        "```\n",
        "\n",
        "> **Lembrete**: Multi-Layer Perceptrons trabalham somente com dados unidimensionais (vetores). Sendo a imagem com dimensionalidade ```(1, 28, 28)```, precisamos linearizá-la antes de alimentar a rede (lembra da função `view`?). Isso implica que o a entrada da rede deve ser redimensionada para ```input_size = 28 x 28 x 1 = 784```\n",
        "\n",
        "> **A dimensionalidade das camadas fica a seu critério.** São fixadas apenas a dimensionalidade da entrada (`784`) e da saída (`args['num_classes'] = 10` previamente definida)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFKs6H07Y_rY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MinhaRede(nn.Module):\n",
        "  \n",
        "  def __init__(self, input_size, hidden1_size, hidden2_size, output_size):\n",
        "    super(MinhaRede, self).__init__()\n",
        "    \n",
        "    # Definir a arquitetura\n",
        "    self.hidden1 = nn.Linear(input_size, hidden1_size)\n",
        "    self.hidden2 = nn.Linear(hidden1_size, hidden2_size)\n",
        "    self.output  = nn.Linear(hidden2_size, output_size)\n",
        "\n",
        "  def forward(self, x):\n",
        "    \n",
        "    x = x.view(x.size(0), -1)\n",
        "    h1 = F.relu(self.hidden1(x))\n",
        "    h2 = F.relu(self.hidden2(h1))\n",
        "    output = F.softmax(self.output(h2))\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZtVYuIwaHZF",
        "colab_type": "text"
      },
      "source": [
        "Instanciando a rede"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLz9rYaCaA_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_size   = 28 * 28\n",
        "hidden1_size = 128\n",
        "hidden2_size = 50\n",
        "out_size     = args['num_classes'] #classes\n",
        "\n",
        "net = MinhaRede(input_size, hidden1_size, hidden1_size, out_size).to(args['device']) #cast na GPU "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zmOfuIU77j7",
        "colab_type": "text"
      },
      "source": [
        "## Função de Perda e Otimizador"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wN0vE_IK8B93",
        "colab_type": "text"
      },
      "source": [
        "Por se tratar de um problema de classificação usaremos a função de custo [`CrossEntropyLoss`](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss).\n",
        "\n",
        "Como ainda não vimos a fundo os otimizadores e suas vantagens, usaremos o já conhecido [`SGD`](https://pytorch.org/docs/stable/optim.html#torch.optim.SGD) da biblioteca `torch.optim`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZQ_Vjqy7-x6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define Loss\n",
        "criterion = nn.CrossEntropyLoss().to(args['device'])\n",
        "\n",
        "# Define Optimizer\n",
        "optimizer = optim.SGD(params=net.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jBCt98yt9SXW",
        "colab_type": "text"
      },
      "source": [
        "## Fluxo de Treinamento\n",
        "\n",
        "**Agora implemente a seguir** um fluxo completo de treinamento. Relembrando o passo a passo:\n",
        "\n",
        "* Iterar nas épocas (Número de épocas definido em `args['num_epochs']`)\n",
        "* Iterar nos batches (*loaders* pré definidos que retornam uma tupla `(dado, rótulo)`)\n",
        "* Cast dos dados no dispositivo de hardware (Dispositivo definido em `args['device']`)\n",
        "* Forward do batch na rede \n",
        "* Cálculo da loss (`criterion` previamente definido)\n",
        "* Cálculo do gradiente a partir da loss (autograd torch)\n",
        "* Atualização dos pesos (`optimizer.step()`)\n",
        "\n",
        "Para acompanhar a convergência do seu modelo (e garantir que tudo foi feito certinho), ao final de cada época podemos imprimir a média e o desvio padrão das perdas de cada iteração."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9OufEK69T7k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds_list = []\n",
        "labels_list = []\n",
        "\n",
        "for epoch in range(args['num_epochs']):\n",
        "  start = time.time()\n",
        "\n",
        "  epoch_loss = []\n",
        "  for batch in train_loader:\n",
        "    \n",
        "    dado, rotulo = batch\n",
        "\n",
        "    # Cast na GPU\n",
        "    dado   = dado.to(args['device'])\n",
        "    rotulo = rotulo.to(args['device'])\n",
        "\n",
        "    # Forward \n",
        "    pred = net(dado)\n",
        "    loss = criterion(pred, rotulo)\n",
        "    epoch_loss.append(loss.cpu().data)\n",
        "\n",
        "    # Predições\n",
        "    preds = pred.data.max(dim=1)[1].cpu().numpy()\n",
        "    preds_list.append(preds)\n",
        "    labels_list.append(rotulo.cpu().numpy())\n",
        "\n",
        "    # Backward\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  epoch_loss = np.asarray(epoch_loss)\n",
        "  acc = metrics.accuracy_score(np.asarray(labels_list).ravel(),\n",
        "                                 np.asarray(preds_list).ravel())\n",
        "\n",
        "  end = time.time()\n",
        "\n",
        "  print(\"Epoca %d, Loss: %.4f +\\- %.4f, Acc: %.2f, Tempo: %.2f\" % (epoch, epoch_loss.mean(), epoch_loss.std(), acc*100, end-start) )\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}