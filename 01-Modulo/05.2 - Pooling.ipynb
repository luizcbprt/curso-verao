{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"01.2 - Pooling.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"gvh-wt988noD"},"source":["# Pooling\n","\n","Muitas vezes, ao processar imagens, queremos gradualmente reduzir a resolução espacial das representações aprendidas (*feature maps*), agregando informações de forma que, quanto mais aprofundarmos na rede, maior o campo receptivo (*receptive field*).\n","\n","Muitas vezes, a tarefa final é relacionada com alguma característica global da imagem como, por exemplo,  na tarefa de classificação de cenas.\n","Então, tipicamente, os neurônios da última camada devem conseguir captar informação da entrada como um todo.\n","Ao agregar gradualmente as informações, produzindo *feature maps* de baixa resolução, alcançamos esse objetivo de aprender uma representação global, mantendo todas as vantagens das camadas convolucionais nas camadas intermediárias de processamento.\n","\n","Além disso, ao detectar características de baixo nível, como bordas, muitas vezes queremos que as representações sejam um pouco invariantes à translação.\n","Por exemplo, suponha uma imagem com uma definição nítida entre preto e branco.\n","Suponha agora que deslocamos toda a imagem em um pixel para a direita.\n","A saída para essa nova imagem pode ser muito diferente.\n","A borda terá mudado em um pixel e, consequentemente, todas as ativações mudarão.\n","Na realidade, os objetos quase nunca ocorrem exatamente no mesmo lugar.\n","De fato, mesmo com um tripé e um objeto estacionário, vibração da câmera devido ao movimento do obturador pode mudar tudo por um pixel ou mais .\n","\n","Nesta prática, veremos as camadas de pooling que tem dois própositos básicas: (i) tornar a representação invariante à translação, e (ii) reduzir espacialmente as características aprendidas, aumentando o *receptive field*.\n","\n","## Max- e Mean-Pooling\n","\n","Como camadas convolucionais, operadores de pooling consistem em uma janela (de tamanho fixo) deslizando sobre todas as regiões na entrada de acordo com seu *stride*, computando uma única saída para cada local visitado.\n","No entanto, ao contrário das camadas convolucionais, a camada de pooling não tem parâmetros (ou seja, ela não aprende nada).\n","Em vez disso, os operadores de pooling são determinísticos, normalmente calculando o valor máximo (*max*) ou médio (*mean*) dos elementos compreendido na sua janela.\n","Essas operações são chamadas de *max-pooling* e *mean-pooling*, respectivamente.\n","\n","Em ambos os casos, como na convolução, podemos pensar que o processo de pooling começa com sua janela no canto superior esquerdo da entrada e a desliza da esquerda para a direita e de cima para baixo.\n","Em cada vizinhança delimitada pela janela, calcula-se o valor máximo ou médio dos pixels daquela região.\n","\n","<p align=\"center\">\n","  <img src=\"https://drive.google.com/uc?export=view&id=17YzoYsvNPAX9OVeSGVIWeiGmsixeywF7\">\n","</p>\n","\n","O array de saída da figura acima tem uma altura de 2 e uma largura de 2.\n","Os quatro elementos são derivados do valor de máximo da vizinhança, ou seja:\n","\n","$$\n","\\max (0,1,3,4) = 4, \\\\\n","\\max (1,2,4,5) = 5, \\\\\n","\\max (3,4,6,7) = 7, \\\\\n","\\max (4,5,7,8) = 8. \\\\\n","$$\n","\n","Vamos retornar ao exemplo de detecção de borda de objeto mencionado no início desta seção. Agora vamos usar a saída da camada convolucional como a entrada para um max-pooling $ 2\\times 2$.\n","Mesmo se a entrada para a camada convolucional se transladar um pixel para qualquer lado, a camada de pooling será capaz de gerar a mesma saída, já que avaliará a vizinhança para produzir a saída.\n","Ou seja, usando uma camada de max-pooling de $2\\times 2$, ainda podemos detectar o padrão reconhecido pela camada convolucional dado que este não se mova mais do que um pixel em altura e largura."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"R6B83S_T8tMn"},"source":["Antes de começar, vamos instalar o Pytorch. Esse pequeno bloco de código abaixo é usado somente para instalar o Pytorch para CUDA 10. Execute esse bloco somente uma vez e ignore possíveis erros levantados durante a instalação.\n","\n","**ATENÇÃO: a alteração deste bloco pode implicar em problemas na execução dos blocos restantes!**"]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"elapsed":5778,"status":"ok","timestamp":1570917243447,"user":{"displayName":"Felipe Marcelino","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC3yhjltVDWqNXwhUpquSUaO9nIa2J0oIFCyJy6VQ=s64","userId":"10589390457938412332"},"user_tz":180},"id":"D1Us3dSB6LZK","outputId":"21331314-8d95-429c-ffcb-3e19d10e3536","colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["!pip3 install torch torchvision"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.2.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.5)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"hJ6975US8ygK","colab":{}},"source":["import time, os, sys, numpy as np\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torch import optim\n","\n","import time, os, sys, numpy as np\n","\n","# Test if GPU is avaliable, if not, use cpu instead\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","n = torch.cuda.device_count()\n","devices_ids= list(range(n))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pm-1flCc82kq","colab":{}},"source":["def load_data_fashion_mnist(batch_size, resize=None, root=os.path.join(\n","        '~', '.pytorch', 'datasets', 'fashion-mnist')):\n","    \"\"\"Download the Fashion-MNIST dataset and then load into memory.\"\"\"\n","    root = os.path.expanduser(root)\n","    transformer = []\n","    if resize:\n","        transformer += [torchvision.transforms.Resize(resize)]\n","    transformer += [torchvision.transforms.ToTensor()]\n","    transformer = torchvision.transforms.Compose(transformer)\n","\n","    mnist_train = torchvision.datasets.FashionMNIST(root=root, train=True,download=True,transform=transformer)\n","    mnist_test = torchvision.datasets.FashionMNIST(root=root, train=False,download=True,transform=transformer)\n","    num_workers = 0 if sys.platform.startswith('win32') else 4\n","\n","\n","\n","    train_iter = torch.utils.data.DataLoader(mnist_train,\n","                                  batch_size, shuffle=True,\n","                                  num_workers=num_workers)\n","    test_iter = torch.utils.data.DataLoader(mnist_test,\n","                                 batch_size, shuffle=False,\n","                                 num_workers=num_workers)\n","    return train_iter, test_iter\n","\n","# funções básicas\n","def _get_batch(batch):\n","    \"\"\"Return features and labels on ctx.\"\"\"\n","    features, labels = batch\n","    if labels.type() != features.type():\n","        labels = labels.type(features.type())\n","    return (torch.nn.DataParallel(features, device_ids=devices_ids),\n","            torch.nn.DataParallel(labels, device_ids=devices_ids), features.shape[0])\n","\n","# Função usada para calcular acurácia\n","def evaluate_accuracy(data_iter, net, loss):\n","    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n","\n","    acc_sum, n, l = torch.Tensor([0]), 0, 0\n","    \n","    with torch.no_grad():\n","      for X, y in data_iter:\n","          #y = y.astype('float32')\n","          X, y = X.to(device), y.to(device)\n","          y_hat = net(X)\n","          l += loss(y_hat, y).sum()\n","          acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n","          n += y.size()[0]\n","\n","    return acc_sum.item() / n, l.item() / len(data_iter)\n","  \n","# Função usada no treinamento e validação da rede\n","def train_validate(net, train_iter, test_iter, batch_size, trainer, loss,\n","                   num_epochs):\n","    print('training on', device)\n","    for epoch in range(num_epochs):\n","        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n","        for X, y in train_iter:\n","            X, y = X.to(device), y.to(device)\n","            y_hat = net(X)\n","            trainer.zero_grad()\n","            l = loss(y_hat, y).sum()\n","            l.backward()\n","            trainer.step()\n","            train_l_sum += l.item()\n","            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n","            n += y.size()[0]\n","        test_acc, test_loss = evaluate_accuracy(test_iter, net, loss)\n","        print('epoch %d, train loss %.4f, train acc %.3f, test loss %.4f, '\n","              'test acc %.3f, time %.1f sec'\n","              % (epoch + 1, train_l_sum / len(train_iter), train_acc_sum / n, test_loss, \n","                 test_acc, time.time() - start))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"qocBsc0N84n-"},"source":["Vamos agora, mostrar como funciona a camada de *pooling* na prática. Em frameworks modernos, camadas de *pooling* já vem implementadas e são fáceis de usar.\n","\n","Abaixo, criamos uma matriz 2-D e a processamos usando um [*max-pooling*](https://mxnet.incubator.apache.org/api/python/gluon/nn.html#mxnet.gluon.nn.MaxPool2D) de $2\\times 2$."]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"elapsed":1025,"status":"ok","timestamp":1570917374186,"user":{"displayName":"Felipe Marcelino","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC3yhjltVDWqNXwhUpquSUaO9nIa2J0oIFCyJy6VQ=s64","userId":"10589390457938412332"},"user_tz":180},"id":"_iD3ggBb84-w","outputId":"61d9e52e-021d-4447-8dec-0434a09b06fc","colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["X = torch.Tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n","print(X)\n","X = X.reshape((1, 1) + X.shape)\n","\n","pool = nn.MaxPool2d(kernel_size=2, stride=1)\n","y = pool(X)\n","\n","print(y)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[0., 1., 2.],\n","        [3., 4., 5.],\n","        [6., 7., 8.]])\n","tensor([[[[4., 5.],\n","          [7., 8.]]]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"elapsed":1339,"status":"ok","timestamp":1570917416296,"user":{"displayName":"Felipe Marcelino","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC3yhjltVDWqNXwhUpquSUaO9nIa2J0oIFCyJy6VQ=s64","userId":"10589390457938412332"},"user_tz":180},"id":"YYbMyq0n-HxV","outputId":"6abddf56-cbcd-4640-beae-84e679bd28ff","colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["X = torch.Tensor([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n","print(X)\n","X = X.reshape((1, 1) + X.shape)\n","\n","pool = nn.AvgPool2d(kernel_size=2, stride=1)\n","y = pool(X)\n","\n","print(y)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([[0., 1., 2.],\n","        [3., 4., 5.],\n","        [6., 7., 8.]])\n","tensor([[[[2., 3.],\n","          [5., 6.]]]])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2RrtzkE6-a8q"},"source":["Ao processar dados com múltiplos canais, a camada de pooling processa cada canal de entrada separadamente ao invés de processar todos os canais como em uma camada convolucional.\n","Isso significa que o número de canais de saída para a camada de pooling é o mesmo que o número de canais de entrada.\n","Abaixo, vamos concatenar X e X + 1 na dimensão do canal para construir uma entrada com 2 canais."]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"elapsed":1570,"status":"ok","timestamp":1570917510510,"user":{"displayName":"Felipe Marcelino","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC3yhjltVDWqNXwhUpquSUaO9nIa2J0oIFCyJy6VQ=s64","userId":"10589390457938412332"},"user_tz":180},"id":"qpP_vEMB-Xeb","outputId":"603518f8-2f6d-4f73-e755-1e907ed66518","colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["X = torch.cat((X, X + 1), dim=1)\n","X"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[[0., 1., 2.],\n","          [3., 4., 5.],\n","          [6., 7., 8.]],\n","\n","         [[1., 2., 3.],\n","          [4., 5., 6.],\n","          [7., 8., 9.]]]])"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"elapsed":1319,"status":"ok","timestamp":1570917531503,"user":{"displayName":"Felipe Marcelino","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC3yhjltVDWqNXwhUpquSUaO9nIa2J0oIFCyJy6VQ=s64","userId":"10589390457938412332"},"user_tz":180},"id":"yNPFMaxq-fJU","outputId":"71064587-c295-4dcd-edf2-31789a7c416f","colab":{"base_uri":"https://localhost:8080/","height":102}},"source":["pool2d = nn.MaxPool2d(kernel_size=2, stride=1)\n","pool2d(X)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[[4., 5.],\n","          [7., 8.]],\n","\n","         [[5., 6.],\n","          [8., 9.]]]])"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"OlDJbg75-2Pa"},"source":["## Padding and Stride\n","\n","Como nas camadas convolucionais, as camadas de pooling também pode alterar as dimensões da saída.\n","Da mesma forma que antes, podemos calcular a saída da camada baseada na sua configuração:\n","\n","\n","$$\\lfloor (n_h-k_h + p_h + s_h) / s_h \\rfloor \\times \\lfloor(n_w-k_w + p_w + s_w) / s_w \\rfloor$$\n","\n","E como antes, podemos configurar a operação para obter uma saída com dimensões desejadas usando *padding* e *stride*.\n","Podemos demonstrar a influência de *padding* e *stride* em camadas de pooling através da camada de max-pooling *MaxPool2d* do framework Pytorch.\n","Primeiro, construímos um dado de entrada com dimensões (1, 1, 4, 4), onde as duas primeiras dimensões são o tamanho do *batch* e canal."]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"elapsed":1407,"status":"ok","timestamp":1570917554735,"user":{"displayName":"Felipe Marcelino","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC3yhjltVDWqNXwhUpquSUaO9nIa2J0oIFCyJy6VQ=s64","userId":"10589390457938412332"},"user_tz":180},"id":"zT-pjwk1-zm9","outputId":"07fed965-c634-4568-db7f-ee777b95b573","colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["X = torch.arange(16).reshape((1, 1, 4, 4))\n","X"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[[ 0,  1,  2,  3],\n","          [ 4,  5,  6,  7],\n","          [ 8,  9, 10, 11],\n","          [12, 13, 14, 15]]]])"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Ub-fBLgl--Ho"},"source":["Por padrão, o *stride*  da *MaxPool2d* tem o mesmo tamanho da janela.\n","Por exemplo, abaixo usamos uma janela de tamanho (3, 3).\n","Como não especificamos explicitamente nenhum *stride*, obtemos um *stride* padrão de tamanho (3, 3)."]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"elapsed":1529,"status":"ok","timestamp":1570917682031,"user":{"displayName":"Felipe Marcelino","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC3yhjltVDWqNXwhUpquSUaO9nIa2J0oIFCyJy6VQ=s64","userId":"10589390457938412332"},"user_tz":180},"id":"df0HB1T1-9Bf","outputId":"53c348da-a5c7-4a81-eb31-cf8f1563937c","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["pool2d = nn.MaxPool2d(kernel_size=3)\n","# Because there are no model parameters in the pooling layer, we do not need\n","# to call the parameter initialization function\n","pool2d(X.float()) # Only works with float"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[[10.]]]])"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"33Gjurer_npV"},"source":["Logicamente, podemos especificar explicitamente o *padding* e o *stride* de uma camada de pooling."]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"elapsed":1412,"status":"ok","timestamp":1570917783073,"user":{"displayName":"Felipe Marcelino","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC3yhjltVDWqNXwhUpquSUaO9nIa2J0oIFCyJy6VQ=s64","userId":"10589390457938412332"},"user_tz":180},"id":"xvkieEua_DQr","outputId":"ec59996e-98d7-407c-b770-004985ad5910","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["pool2d = nn.MaxPool2d(kernel_size=3, padding=1, stride=2)\n","pool2d(X.float())"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[[ 5.,  7.],\n","          [13., 15.]]]])"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"dh48hAIi_zhf"},"source":["Podemos, também, especificar o tamanho de uma janela retangular arbitrária, do *padding* e do *stride* para altura e largura, respectivamente."]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"elapsed":1407,"status":"ok","timestamp":1570918028459,"user":{"displayName":"Felipe Marcelino","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC3yhjltVDWqNXwhUpquSUaO9nIa2J0oIFCyJy6VQ=s64","userId":"10589390457938412332"},"user_tz":180},"id":"TI62DrQY_sn4","outputId":"92133bd7-fc2e-43c6-f39d-429ee809bf7d","colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["pool2d = nn.MaxPool2d(kernel_size=(2, 4), padding=(1, 2), stride=(2, 3))\n","pool2d(X.float())"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[[ 1.,  3.],\n","          [ 9., 11.],\n","          [13., 15.]]]])"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"uSD73dozA67D"},"source":["## Pytorch e o caso de estudo LeNet-5\n","\n","Agora vamos implementar a [LeNet-5](https://ieeexplore.ieee.org/document/726791) completa usando Pytorch.\n","\n","<p align=\"center\">\n","  <img width=700 src=\"https://miro.medium.com/max/2625/1*1TI1aGBZ4dybR6__DI9dzA.png\">\n","</p>\n","\n","<p align=\"center\">\n","  <img width=700 src=\"https://engmrk.com/wp-content/uploads/2018/09/LeNEt_Summary_Table.jpg\">\n","</p>"]},{"cell_type":"code","metadata":{"colab_type":"code","executionInfo":{"status":"ok","timestamp":1570923782498,"user_tz":180,"elapsed":108824,"user":{"displayName":"Felipe Marcelino","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC3yhjltVDWqNXwhUpquSUaO9nIa2J0oIFCyJy6VQ=s64","userId":"10589390457938412332"}},"id":"eRqh5loP_6YL","outputId":"94e08143-51d3-4e5e-b00a-5fb581d0deb1","colab":{"base_uri":"https://localhost:8080/","height":204}},"source":["# parâmetros: número de epochs, learning rate (ou taxa de aprendizado), \n","# tamanho do batch, e lambda do weight decay\n","num_epochs, lr, batch_size, wd_lambda = 10, 0.1, 128, 0.000001\n","\n","# rede baseada na LeNet-5 \n","net = nn.Sequential(nn.Conv2d(in_channels=1,out_channels=6, kernel_size=5, stride=1, padding=0),   # entrada: (b, 1, 32, 32) e saida: (b, 6, 28, 28)\n","        nn.Tanh(),\n","        nn.AvgPool2d(kernel_size=2, stride=2, padding=0),                        # entrada: (b, 6, 28, 28) e saida: (b, 6, 14, 14)\n","        nn.Conv2d(in_channels=6,out_channels=16, kernel_size=5, stride=1, padding=0),  # entrada: (b, 6, 14, 14) e saida: (b, 16, 10, 10)\n","        nn.Tanh(),\n","        nn.AvgPool2d(kernel_size=2, stride=2, padding=0),                        # entrada: (b, 16, 10, 10) e saida: (b, 16, 5, 5)\n","        nn.Conv2d(in_channels=16,out_channels=120, kernel_size=5, stride=1, padding=0), # entrada: (b, 16, 5, 5) e saida: (b, 120, 1, 1)\n","        nn.Tanh(),\n","        nn.Flatten(),  # lineariza formando um vetor                            # entrada: (b, 120, 1, 1) e saida: (b, 120*1*1) = (b, 120)\n","        nn.Linear(120, 84),                                        # entrada: (b, 120) e saida: (b, 84)\n","        nn.Tanh(),\n","        nn.Linear(84,10))      \n","                                                     # entrada: (b, 84) e saida: (b, 10)\n","# Sending model to device\n","net.to(device)\n","\n","# função de custo (ou loss)\n","loss = nn.CrossEntropyLoss()\n","\n","# carregamento do dado: mnist\n","train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=32)\n","\n","# trainer do gluon\n","trainer = optim.SGD(net.parameters(), lr=lr, weight_decay=wd_lambda, momentum=0.9)\n","\n","# treinamento e validação via Pytorch\n","train_validate(net, train_iter, test_iter, batch_size, trainer, loss, \n","                num_epochs)"],"execution_count":35,"outputs":[{"output_type":"stream","text":["training on cuda\n","epoch 1, train loss 0.6146, train acc 0.769, test loss 0.4244, test acc 0.846, time 10.6 sec\n","epoch 2, train loss 0.3913, train acc 0.857, test loss 0.4201, test acc 0.848, time 10.8 sec\n","epoch 3, train loss 0.3476, train acc 0.872, test loss 0.3821, test acc 0.859, time 10.6 sec\n","epoch 4, train loss 0.3225, train acc 0.881, test loss 0.3754, test acc 0.864, time 10.8 sec\n","epoch 5, train loss 0.3059, train acc 0.888, test loss 0.3611, test acc 0.867, time 10.7 sec\n","epoch 6, train loss 0.2849, train acc 0.894, test loss 0.3614, test acc 0.861, time 10.6 sec\n","epoch 7, train loss 0.2686, train acc 0.900, test loss 0.3132, test acc 0.887, time 10.8 sec\n","epoch 8, train loss 0.2568, train acc 0.904, test loss 0.3259, test acc 0.887, time 10.8 sec\n","epoch 9, train loss 0.2489, train acc 0.906, test loss 0.3398, test acc 0.878, time 10.7 sec\n","epoch 10, train loss 0.2337, train acc 0.913, test loss 0.3040, test acc 0.889, time 10.9 sec\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MxR-vCgTCR5l","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}