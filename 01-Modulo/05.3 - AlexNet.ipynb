{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"01.3 - AlexNet.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"QRV_7PdLIXhh","colab_type":"text"},"source":["# Prática: Redes Neurais Convolucionais\n","\n","Vamos agora implementar a rede [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf), uma das redes que trouxeram todo esse interesse para a área de *deep learning*.\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"2wMF3fPNIYGQ","colab_type":"code","outputId":"78157532-4da3-439e-bb3f-9d6d94cf880c","executionInfo":{"status":"ok","timestamp":1570920084191,"user_tz":180,"elapsed":4322,"user":{"displayName":"Felipe Marcelino","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC3yhjltVDWqNXwhUpquSUaO9nIa2J0oIFCyJy6VQ=s64","userId":"10589390457938412332"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["!pip3 install torch torchvision"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.2.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.16.5)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (4.3.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision) (0.46)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"EAgvY5eBIc1s","colab_type":"code","colab":{}},"source":["import time, os, sys, numpy as np\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torch import optim\n","from torchsummary import summary\n","\n","\n","import time, os, sys, numpy as np\n","\n","# Test if GPU is avaliable, if not, use cpu instead\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","n = torch.cuda.device_count()\n","devices_ids= list(range(n))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xru0TyJXIjGp","colab_type":"code","colab":{}},"source":["def load_data_cifar10(batch_size, resize=None, root=os.path.join(\n","        '~', '.pytorch', 'datasets', 'fashion-mnist')):\n","    \"\"\"Download the Cifar10-MNIST dataset and then load into memory.\"\"\"\n","    root = os.path.expanduser(root)\n","    transformer = []\n","    if resize:\n","        transformer += [torchvision.transforms.Resize(resize)]\n","    transformer += [torchvision.transforms.ToTensor()]\n","    transformer = torchvision.transforms.Compose(transformer)\n","\n","    mnist_train = torchvision.datasets.CIFAR10(root=root, train=True,download=True,transform=transformer)\n","    mnist_test = torchvision.datasets.CIFAR10(root=root, train=False,download=True,transform=transformer)\n","    num_workers = 0 if sys.platform.startswith('win32') else 4\n","\n","\n","\n","    train_iter = torch.utils.data.DataLoader(mnist_train,\n","                                  batch_size, shuffle=True,\n","                                  num_workers=num_workers)\n","    test_iter = torch.utils.data.DataLoader(mnist_test,\n","                                 batch_size, shuffle=False,\n","                                 num_workers=num_workers)\n","    return train_iter, test_iter\n","\n","# funções básicas\n","def _get_batch(batch):\n","    \"\"\"Return features and labels on ctx.\"\"\"\n","    features, labels = batch\n","    if labels.type() != features.type():\n","        labels = labels.type(features.type())\n","    return (torch.nn.DataParallel(features, device_ids=devices_ids),\n","            torch.nn.DataParallel(labels, device_ids=devices_ids), features.shape[0])\n","\n","# Função usada para calcular acurácia\n","def evaluate_accuracy(data_iter, net, loss):\n","    \"\"\"Evaluate accuracy of a model on the given data set.\"\"\"\n","\n","    acc_sum, n, l = torch.Tensor([0]), 0, 0\n","    \n","    with torch.no_grad():\n","      for X, y in data_iter:\n","          #y = y.astype('float32')\n","          X, y = X.to(device), y.to(device)\n","          y_hat = net(X)\n","          l += loss(y_hat, y).sum()\n","          acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n","          n += y.size()[0]\n","\n","    return acc_sum.item() / n, l.item() / len(data_iter)\n","  \n","# Função usada no treinamento e validação da rede\n","def train_validate(net, train_iter, test_iter, batch_size, trainer, loss,\n","                   num_epochs):\n","    print('training on', device)\n","    for epoch in range(num_epochs):\n","        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n","        for X, y in train_iter:\n","            X, y = X.to(device), y.to(device)\n","            y_hat = net(X)\n","            trainer.zero_grad()\n","            l = loss(y_hat, y).sum()\n","            l.backward()\n","            trainer.step()\n","            train_l_sum += l.item()\n","            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().item()\n","            n += y.size()[0]\n","        test_acc, test_loss = evaluate_accuracy(test_iter, net, loss)\n","        print('epoch %d, train loss %.4f, train acc %.3f, test loss %.4f, '\n","              'test acc %.3f, time %.1f sec'\n","              % (epoch + 1, train_l_sum / len(train_iter), train_acc_sum / n, test_loss, \n","                 test_acc, time.time() - start))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TO6YizcSIpiH","colab_type":"text"},"source":["## AlexNet\n","\n","Agora já temos todo o conhecimento necessário para implementar nossa primeira arquitetura moderna.\n","Vamos implementar a [AlexNet](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf), uma das arquiteturas mais famosas dessa nova onda de rede neurais.\n","\n","<p align=\"center\">\n","  <img width=700 src=\"https://www.researchgate.net/profile/Jaime_Gallego2/publication/318168077/figure/fig1/AS:578190894927872@1514862859810/AlexNet-CNN-architecture-layers.png\">\n","</p>\n","\n","<p align=\"center\">\n","  <img width=700 src=\"https://engmrk.com/wp-content/uploads/2018/10/AlexNet_Summary_Table.jpg\">\n","</p>\n"]},{"cell_type":"code","metadata":{"id":"LMWfNHpvIoRR","colab_type":"code","outputId":"629668fb-13bc-462b-8a51-fe8227ed326d","executionInfo":{"status":"ok","timestamp":1570926123834,"user_tz":180,"elapsed":3088373,"user":{"displayName":"Felipe Marcelino","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mC3yhjltVDWqNXwhUpquSUaO9nIa2J0oIFCyJy6VQ=s64","userId":"10589390457938412332"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# parâmetros: número de epochs, learning rate (ou taxa de aprendizado), \n","# tamanho do batch, e lambda do weight decay\n","num_epochs, lr, batch_size, wd_lambda = 20, 0.001, 100, 0.0001\n","\n","# Implementa sua rede neural aqui\n","# Voce pode implementar criando uma variavel net e adicionando as camadas net = nn.Sequential()\n","# Ou pode criar como uma classe(Preferido, pois fica mais organizado e é mais facilitado para um debug da rede)\n","# rede baseada na AlexNet-5 \n","\n","\n","# Sending model to device\n","net.to(device)\n","print(summary(net,(3,227,227))) # visualize number of parameters' net, output of each layer and total mega bytes necessary for forward pass\n","                                # and stored weights. \n","\n","# função de custo (ou loss)\n","loss = nn.CrossEntropyLoss()\n","\n","# carregamento do dado: mnist\n","train_iter, test_iter = load_data_cifar10(batch_size, resize=227)\n","\n","# trainer do gluon\n","trainer = optim.Adam(net.parameters(), lr=lr, weight_decay=wd_lambda)\n","\n","# treinamento e validação via Pytorch\n","train_validate(net, train_iter, test_iter, batch_size, trainer, loss, \n","                num_epochs)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1           [-1, 96, 55, 55]          34,944\n","              ReLU-2           [-1, 96, 55, 55]               0\n","         MaxPool2d-3           [-1, 96, 27, 27]               0\n","              ReLU-4           [-1, 96, 27, 27]               0\n","            Conv2d-5          [-1, 256, 27, 27]         614,656\n","              ReLU-6          [-1, 256, 27, 27]               0\n","         MaxPool2d-7          [-1, 256, 13, 13]               0\n","              ReLU-8          [-1, 256, 13, 13]               0\n","            Conv2d-9          [-1, 384, 13, 13]         885,120\n","             ReLU-10          [-1, 384, 13, 13]               0\n","           Conv2d-11          [-1, 384, 13, 13]       1,327,488\n","             ReLU-12          [-1, 384, 13, 13]               0\n","           Conv2d-13          [-1, 256, 13, 13]         884,992\n","             ReLU-14          [-1, 256, 13, 13]               0\n","        MaxPool2d-15            [-1, 256, 6, 6]               0\n","             ReLU-16            [-1, 256, 6, 6]               0\n","          Flatten-17                 [-1, 9216]               0\n","           Linear-18                 [-1, 4096]      37,752,832\n","             ReLU-19                 [-1, 4096]               0\n","           Linear-20                 [-1, 4096]      16,781,312\n","             ReLU-21                 [-1, 4096]               0\n","           Linear-22                   [-1, 10]          40,970\n","================================================================\n","Total params: 58,322,314\n","Trainable params: 58,322,314\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.59\n","Forward/backward pass size (MB): 11.98\n","Params size (MB): 222.48\n","Estimated Total Size (MB): 235.06\n","----------------------------------------------------------------\n","None\n","Files already downloaded and verified\n","Files already downloaded and verified\n","training on cuda\n","epoch 1, train loss 0.0199, train acc 0.249, test loss 0.0167, test acc 0.391, time 154.4 sec\n","epoch 2, train loss 0.0148, train acc 0.453, test loss 0.0132, test acc 0.520, time 154.4 sec\n","epoch 3, train loss 0.0126, train acc 0.544, test loss 0.0121, test acc 0.575, time 154.9 sec\n","epoch 4, train loss 0.0109, train acc 0.608, test loss 0.0107, test acc 0.623, time 154.7 sec\n","epoch 5, train loss 0.0096, train acc 0.660, test loss 0.0100, test acc 0.647, time 154.7 sec\n","epoch 6, train loss 0.0085, train acc 0.698, test loss 0.0099, test acc 0.659, time 154.8 sec\n","epoch 7, train loss 0.0076, train acc 0.731, test loss 0.0101, test acc 0.660, time 154.6 sec\n","epoch 8, train loss 0.0068, train acc 0.759, test loss 0.0100, test acc 0.660, time 154.8 sec\n","epoch 9, train loss 0.0060, train acc 0.788, test loss 0.0098, test acc 0.679, time 154.6 sec\n","epoch 10, train loss 0.0051, train acc 0.817, test loss 0.0102, test acc 0.677, time 154.8 sec\n","epoch 11, train loss 0.0045, train acc 0.840, test loss 0.0119, test acc 0.651, time 154.7 sec\n","epoch 12, train loss 0.0039, train acc 0.860, test loss 0.0123, test acc 0.670, time 154.2 sec\n","epoch 13, train loss 0.0032, train acc 0.885, test loss 0.0129, test acc 0.659, time 153.7 sec\n","epoch 14, train loss 0.0028, train acc 0.901, test loss 0.0142, test acc 0.658, time 153.1 sec\n","epoch 15, train loss 0.0025, train acc 0.912, test loss 0.0140, test acc 0.665, time 154.1 sec\n","epoch 16, train loss 0.0022, train acc 0.921, test loss 0.0158, test acc 0.659, time 153.1 sec\n","epoch 17, train loss 0.0020, train acc 0.928, test loss 0.0167, test acc 0.658, time 153.2 sec\n","epoch 18, train loss 0.0018, train acc 0.934, test loss 0.0174, test acc 0.662, time 153.5 sec\n","epoch 19, train loss 0.0017, train acc 0.941, test loss 0.0183, test acc 0.653, time 154.5 sec\n","epoch 20, train loss 0.0017, train acc 0.941, test loss 0.0177, test acc 0.659, time 154.5 sec\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ncph4JFcKsII","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}